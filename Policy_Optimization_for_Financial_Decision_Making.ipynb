{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShauryaDamathia/ShodhAI_Policy_Optimization/blob/main/Policy_Optimization_for_Financial_Decision_Making.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1_EDA_and_Preprocessing.ipynb**"
      ],
      "metadata": {
        "id": "swFD72dPxZvY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jzHdfz8UrVBb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('accepted_2007_to_2018Q4.csv', nrows=500000)"
      ],
      "metadata": {
        "id": "xGDooMtlt3C6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Initial Data Overview ---\")\n",
        "print(df.info())\n",
        "print(\"\\n--- Summary Statistics ---\")\n",
        "print(df.describe())"
      ],
      "metadata": {
        "id": "QAi5HZ-xt3Fu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "sns.countplot(y='loan_status', data=df)\n",
        "plt.title('Distribution of Loan Status')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t_tiWggzt3IS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_features = [\n",
        "    'loan_amnt', 'int_rate', 'installment', 'grade', 'sub_grade', 'emp_length',\n",
        "    'home_ownership', 'annual_inc', 'verification_status', 'purpose', 'dti',\n",
        "    'delinq_2yrs', 'fico_range_high', 'inq_last_6mths', 'pub_rec', 'revol_bal',\n",
        "    'revol_util', 'total_acc', 'loan_status'\n",
        "]\n",
        "df = df[selected_features]\n",
        "\n",
        "print(f\"\\n--- Working with {len(df.columns)-1} selected features ---\")"
      ],
      "metadata": {
        "id": "xa_tx3DDt3NX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[df['loan_status'].isin(['Fully Paid', 'Charged Off'])]\n",
        "df['loan_status'] = df['loan_status'].apply(lambda x: 0 if x == 'Fully Paid' else 1)\n",
        "print(\"\\n--- Target Variable Distribution (0: Paid, 1: Default) ---\")\n",
        "print(df['loan_status'].value_counts(normalize=True))"
      ],
      "metadata": {
        "id": "jc5tU_ORt3QL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
        "for col in numeric_cols:\n",
        "    if df[col].isnull().sum() > 0:\n",
        "        df[col].fillna(df[col].median(), inplace=True)\n",
        "\n",
        "df.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "5mOKGS4bt3Sl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['emp_length'] = df['emp_length'].str.replace(r'\\D', '', regex=True)\n",
        "df['emp_length'] = pd.to_numeric(df['emp_length'], errors='coerce')\n",
        "df['emp_length'].fillna(0, inplace=True)"
      ],
      "metadata": {
        "id": "Vt9nrkTuuFQL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
        "df_encoded = pd.get_dummies(df, columns=categorical_cols, drop_first=True)"
      ],
      "metadata": {
        "id": "9L9mjp23uFS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_encoded.drop('loan_status', axis=1)\n",
        "y = df_encoded['loan_status']"
      ],
      "metadata": {
        "id": "AaCoVO44uFVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
      ],
      "metadata": {
        "id": "V2v_G86ruRbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "print(\"\\n--- Data Preprocessing Complete ---\")\n",
        "print(f\"Training data shape: {X_train.shape}\")\n",
        "print(f\"Test data shape: {X_test.shape}\")"
      ],
      "metadata": {
        "id": "hlngbYFtuRdm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_unscaled = scaler.inverse_transform(X_test)\n",
        "df_test = pd.DataFrame(X_test_unscaled, columns=X.columns)\n",
        "df_test['loan_status'] = y_test.values\n",
        "\n",
        "df_test.to_csv('preprocessed_test_data.csv', index=False)"
      ],
      "metadata": {
        "id": "TILIsRESuRgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('X_train.npy', X_train)\n",
        "np.save('X_test.npy', X_test)\n",
        "np.save('y_train.npy', y_train)\n",
        "np.save('y_test.npy', y_test)"
      ],
      "metadata": {
        "id": "MQaNmttxu4et"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2_Deep_Learning_Model.ipynb**"
      ],
      "metadata": {
        "id": "WFcLkJvFxeXi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import roc_auc_score, f1_score, roc_curve, auc\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "6YrlYkKYxhNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.load('X_train.npy')\n",
        "X_test = np.load('X_test.npy')\n",
        "y_train = np.load('y_train.npy')\n",
        "y_test = np.load('y_test.npy')\n",
        "print(\"--- Data Loaded Successfully ---\")\n",
        "print(f\"Training data shape: {X_train.shape}\")"
      ],
      "metadata": {
        "id": "QIqBlgt9xhkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dropout(0.3),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=[tf.keras.metrics.AUC(name='auc')])\n",
        "\n",
        "print(\"\\n--- Model Summary ---\")\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "nK579klAxhhf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                    validation_split=0.2,\n",
        "                    epochs=100,\n",
        "                    batch_size=256,\n",
        "                    callbacks=[early_stopping],\n",
        "                    verbose=1)\n",
        "\n",
        "y_pred_proba = model.predict(X_test).ravel()\n",
        "y_pred_class = (y_pred_proba > 0.5).astype(int)"
      ],
      "metadata": {
        "id": "EPoGQrhixhfC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "auc_score = roc_auc_score(y_test, y_pred_proba)\n",
        "f1 = f1_score(y_test, y_pred_class)\n",
        "\n",
        "print(\"\\n--- Model Evaluation on Test Set ---\")\n",
        "print(f\"AUC Score: {auc_score:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")"
      ],
      "metadata": {
        "id": "EnvzgqtTxhcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('loan_default_model.h5')\n",
        "print(\"\\n--- Model saved successfully as 'loan_default_model.h5' ---\")"
      ],
      "metadata": {
        "id": "wA1P5GPhc9gs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1h907FUjxhP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Loss Over Epochs')\n",
        "plt.legend()\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['auc'], label='Training AUC')\n",
        "plt.plot(history.history['val_auc'], label='Validation AUC')\n",
        "plt.title('AUC Over Epochs')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Fw7oCFd3ySDz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3_Offline_RL_Agent.ipynb**"
      ],
      "metadata": {
        "id": "c4LL8lCQxkIC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install d3rlpy"
      ],
      "metadata": {
        "id": "fC997juYRET6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import d3rlpy\n",
        "from d3rlpy.algos import DiscreteCQL, DiscreteCQLConfig\n",
        "from d3rlpy.dataset import MDPDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os"
      ],
      "metadata": {
        "id": "j5hN3ETGb3Uv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    df_test = pd.read_csv('preprocessed_test_data.csv')\n",
        "    X_test_scaled = np.load('X_test.npy')\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"Error: {e}. Make sure you have run the first notebook (1_EDA_and_Preprocessing.ipynb) successfully.\")\n",
        "    # Exit or handle the error appropriately in a real script\n",
        "    # For a notebook, this print statement will suffice.\n",
        "\n",
        "print(\"--- Test Data Loaded ---\")\n",
        "if len(df_test) != len(X_test_scaled):\n",
        "    raise ValueError(\"Mismatch between the length of the dataframe and the scaled features array.\")"
      ],
      "metadata": {
        "id": "uX6jXwECb3R2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "observations = X_test_scaled.astype('float32')\n",
        "num_samples = len(df_test)\n",
        "actions = np.ones(num_samples, dtype=int) # Historical action was always 'Approve' (1)\n",
        "rewards = np.where(\n",
        "    df_test['loan_status'] == 0, # If Fully Paid\n",
        "    df_test['loan_amnt'] * (df_test['int_rate'] / 100),\n",
        "    -df_test['loan_amnt'] # If Defaulted\n",
        ").astype('float32').reshape(-1, 1) # Reshape to a 2D column vector\n",
        "terminals = np.ones(num_samples)\n"
      ],
      "metadata": {
        "id": "QkzW7xs4b3O1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_obs, test_obs, \\\n",
        "train_act, test_act, \\\n",
        "train_rew, test_rew, \\\n",
        "train_term, test_term = train_test_split(\n",
        "    observations, actions, rewards, terminals, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Create an MDPDataset for training ONLY\n",
        "train_dataset = MDPDataset(\n",
        "    observations=train_obs,\n",
        "    actions=train_act,\n",
        "    rewards=train_rew,\n",
        "    terminals=train_term\n",
        ")"
      ],
      "metadata": {
        "id": "NUGnozm2b3MD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Configuring and Training the RL Agent ---\")\n",
        "config = DiscreteCQLConfig()\n",
        "cql = DiscreteCQL(\n",
        "    config=config,\n",
        "    device=\"cpu\",\n",
        "    enable_ddp=False\n",
        ")\n",
        "\n",
        "# Fit the model on the training dataset without any complex evaluation hooks\n",
        "cql.fit(\n",
        "    dataset=train_dataset,\n",
        "    n_steps=50000  # A reasonable number of training steps for a demonstration\n",
        ")\n",
        "print(\"--- Training Complete ---\")"
      ],
      "metadata": {
        "id": "rszi6EUKb3Du"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Manually Evaluating the Trained Policy ---\")\n",
        "\n",
        "policy_actions_on_test_set = cql.predict(test_obs)\n",
        "\n",
        "approved_indices = np.where(policy_actions_on_test_set == 1)[0]\n",
        "\n",
        "rewards_of_approved_loans = test_rew[approved_indices]\n",
        "\n",
        "if len(rewards_of_approved_loans) > 0:\n",
        "    estimated_policy_value = rewards_of_approved_loans.mean()\n",
        "else:\n",
        "    estimated_policy_value = 0.0\n",
        "\n",
        "\n",
        "print(\"\\n--- RL Agent Evaluation Results ---\")\n",
        "print(f\"Policy approved {len(approved_indices)} out of {len(test_obs)} loans in the test set.\")\n",
        "print(f\"Estimated Policy Value (mean return): ${estimated_policy_value:.2f}\")\n",
        "print(\"This value represents the average expected profit for each loan the policy chooses to approve.\")"
      ],
      "metadata": {
        "id": "HKrkqnx9cMwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Comparing DL and RL Policies ---\")\n",
        "# Use the full observation set for a complete comparison\n",
        "rl_actions_full = cql.predict(observations)\n",
        "df_test['rl_decision'] = rl_actions_full\n",
        "\n",
        "model_path = 'loan_default_model.h5'\n",
        "if os.path.exists(model_path):\n",
        "    dl_model = tf.keras.models.load_model(model_path)\n",
        "    dl_pred_proba = dl_model.predict(X_test_scaled).ravel()\n",
        "\n",
        "    dl_threshold = 0.20\n",
        "    df_test['dl_decision'] = (dl_pred_proba < dl_threshold).astype(int)\n",
        "    df_test['dl_default_prob'] = dl_pred_proba\n",
        "\n",
        "    disagreements = df_test[df_test['rl_decision'] != df_test['dl_decision']]\n",
        "    print(f\"\\nFound {len(disagreements)} cases where DL and RL policies disagree.\")\n",
        "\n",
        "    rl_approves_dl_denies = disagreements[disagreements['rl_decision'] == 1].head()\n",
        "    if not rl_approves_dl_denies.empty:\n",
        "        print(\"\\n--- Example: RL Approves, DL Denies ---\")\n",
        "        print(\"The DL model sees high risk (>20% default prob), but the RL agent approves.\")\n",
        "        print(\"This happens when the potential interest profit (reward) outweighs the default risk.\")\n",
        "\n",
        "        display_cols = ['loan_amnt', 'int_rate', 'annual_inc', 'fico_range_high', 'loan_status',\n",
        "                        'dl_default_prob', 'rl_decision', 'dl_decision']\n",
        "        print(rl_approves_dl_denies[display_cols].round(2))\n",
        "    else:\n",
        "        print(\"\\nFound no examples where the RL agent approves and the DL model denies in the first few disagreements.\")\n",
        "\n",
        "else:\n",
        "    print(f\"\\nCould not find '{model_path}'.\")\n",
        "    print(\"Please run Notebook 2 (2_Deep_Learning_Model.ipynb) first to create the model file.\")"
      ],
      "metadata": {
        "id": "zOTV1fumcMta",
        "outputId": "d4adfb82-0045-4e0d-bdb0-99f9c3ef554e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Comparing DL and RL Policies ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "\n",
            "Found 455 cases where DL and RL policies disagree.\n",
            "\n",
            "--- Example: RL Approves, DL Denies ---\n",
            "The DL model sees high risk (>20% default prob), but the RL agent approves.\n",
            "This happens when the potential interest profit (reward) outweighs the default risk.\n",
            "   loan_amnt  int_rate  annual_inc  fico_range_high  loan_status  \\\n",
            "0    11475.0     21.48     35000.0            664.0            0   \n",
            "2    22950.0     17.97    115000.0            694.0            0   \n",
            "4    12000.0     17.97     40000.0            679.0            0   \n",
            "7    27275.0     21.48     62000.0            674.0            1   \n",
            "8     8000.0     16.59     27000.0            664.0            1   \n",
            "\n",
            "   dl_default_prob  rl_decision  dl_decision  \n",
            "0             0.61            1            0  \n",
            "2             0.45            1            0  \n",
            "4             0.40            1            0  \n",
            "7             0.61            1            0  \n",
            "8             0.47            1            0  \n"
          ]
        }
      ]
    }
  ]
}